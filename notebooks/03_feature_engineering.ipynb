{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting statsmodels>=0.9.0 (from category_encoders)\n",
      "  Using cached statsmodels-0.14.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from category_encoders) (2.3.2)\n",
      "Collecting patsy>=0.5.1 (from category_encoders)\n",
      "  Using cached patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/asparikh30/Library/Python/3.9/lib/python/site-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
      "Downloading category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
      "Using cached patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Using cached statsmodels-0.14.5-cp39-cp39-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "Installing collected packages: patsy, statsmodels, category_encoders\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [category_encoders]category_encoders]\n",
      "\u001b[1A\u001b[2KSuccessfully installed category_encoders-2.6.4 patsy-1.0.2 statsmodels-0.14.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.2\n",
      "NumPy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## import scikit learn as sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SCMS_Delivery_History_Dataset.csv from s3://ml-supplychain-project ...\n",
      "Data read successfully in df!\n",
      "   ID Project Code            PQ # PO / SO # ASN/DN #        Country  \\\n",
      "0   1   100-CI-T01  Pre-PQ Process    SCMS-4    ASN-8  Côte d'Ivoire   \n",
      "1   3   108-VN-T01  Pre-PQ Process   SCMS-13   ASN-85        Vietnam   \n",
      "2   4   100-CI-T01  Pre-PQ Process   SCMS-20   ASN-14  Côte d'Ivoire   \n",
      "3  15   108-VN-T01  Pre-PQ Process   SCMS-78   ASN-50        Vietnam   \n",
      "4  16   108-VN-T01  Pre-PQ Process   SCMS-81   ASN-55        Vietnam   \n",
      "\n",
      "  Managed By  Fulfill Via Vendor INCO Term Shipment Mode  ...  \\\n",
      "0   PMO - US  Direct Drop              EXW           Air  ...   \n",
      "1   PMO - US  Direct Drop              EXW           Air  ...   \n",
      "2   PMO - US  Direct Drop              FCA           Air  ...   \n",
      "3   PMO - US  Direct Drop              EXW           Air  ...   \n",
      "4   PMO - US  Direct Drop              EXW           Air  ...   \n",
      "\n",
      "  Unit of Measure (Per Pack) Line Item Quantity Line Item Value Pack Price  \\\n",
      "0                         30                 19           551.0      29.00   \n",
      "1                        240               1000          6200.0       6.20   \n",
      "2                        100                500         40000.0      80.00   \n",
      "3                         60              31920        127360.8       3.99   \n",
      "4                         60              38000        121600.0       3.20   \n",
      "\n",
      "  Unit Price             Manufacturing Site First Line Designation  \\\n",
      "0       0.97     Ranbaxy Fine Chemicals LTD                    Yes   \n",
      "1       0.03      Aurobindo Unit III, India                    Yes   \n",
      "2       0.80  ABBVIE GmbH & Co.KG Wiesbaden                    Yes   \n",
      "3       0.07  Ranbaxy, Paonta Shahib, India                    Yes   \n",
      "4       0.05      Aurobindo Unit III, India                    Yes   \n",
      "\n",
      "  Weight (Kilograms) Freight Cost (USD) Line Item Insurance (USD)  \n",
      "0                 13             780.34                       NaN  \n",
      "1                358             4521.5                       NaN  \n",
      "2                171            1653.78                       NaN  \n",
      "3               1855           16007.06                       NaN  \n",
      "4               7590           45450.08                       NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data from S3 using the existing script\n",
    "%run ../src/read_s3_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created:\n",
      "- vendor_country_combo: 361 unique values\n",
      "- mode_country_combo: 97 unique values\n",
      "- vendor_mode_combo: 102 unique values\n"
     ]
    }
   ],
   "source": [
    "# Interaction features\n",
    "# Vendor-Country combination (encode as categorical)\n",
    "df['vendor_country_combo'] = df['Vendor'].astype(str) + '_' + df['Country'].astype(str)\n",
    "\n",
    "# Shipment mode-Country combination\n",
    "df['mode_country_combo'] = df['Shipment Mode'].astype(str) + '_' + df['Country'].astype(str)\n",
    "\n",
    "# Vendor-Mode combination\n",
    "df['vendor_mode_combo'] = df['Vendor'].astype(str) + '_' + df['Shipment Mode'].astype(str)\n",
    "\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "print(f\"- vendor_country_combo: {df['vendor_country_combo'].nunique()} unique values\")\n",
    "print(f\"- mode_country_combo: {df['mode_country_combo'].nunique()} unique values\")\n",
    "print(f\"- vendor_mode_combo: {df['vendor_mode_combo'].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Project Code</th>\n",
       "      <th>PQ #</th>\n",
       "      <th>PO / SO #</th>\n",
       "      <th>ASN/DN #</th>\n",
       "      <th>Country</th>\n",
       "      <th>Managed By</th>\n",
       "      <th>Fulfill Via</th>\n",
       "      <th>Vendor INCO Term</th>\n",
       "      <th>Shipment Mode</th>\n",
       "      <th>...</th>\n",
       "      <th>Pack Price</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Manufacturing Site</th>\n",
       "      <th>First Line Designation</th>\n",
       "      <th>Weight (Kilograms)</th>\n",
       "      <th>Freight Cost (USD)</th>\n",
       "      <th>Line Item Insurance (USD)</th>\n",
       "      <th>vendor_country_combo</th>\n",
       "      <th>mode_country_combo</th>\n",
       "      <th>vendor_mode_combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100-CI-T01</td>\n",
       "      <td>Pre-PQ Process</td>\n",
       "      <td>SCMS-4</td>\n",
       "      <td>ASN-8</td>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>...</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>Ranbaxy Fine Chemicals LTD</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13</td>\n",
       "      <td>780.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANBAXY Fine Chemicals LTD._Côte d'Ivoire</td>\n",
       "      <td>Air_Côte d'Ivoire</td>\n",
       "      <td>RANBAXY Fine Chemicals LTD._Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108-VN-T01</td>\n",
       "      <td>Pre-PQ Process</td>\n",
       "      <td>SCMS-13</td>\n",
       "      <td>ASN-85</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>...</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Aurobindo Unit III, India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>358</td>\n",
       "      <td>4521.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aurobindo Pharma Limited_Vietnam</td>\n",
       "      <td>Air_Vietnam</td>\n",
       "      <td>Aurobindo Pharma Limited_Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100-CI-T01</td>\n",
       "      <td>Pre-PQ Process</td>\n",
       "      <td>SCMS-20</td>\n",
       "      <td>ASN-14</td>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>FCA</td>\n",
       "      <td>Air</td>\n",
       "      <td>...</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>ABBVIE GmbH &amp; Co.KG Wiesbaden</td>\n",
       "      <td>Yes</td>\n",
       "      <td>171</td>\n",
       "      <td>1653.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbott GmbH &amp; Co. KG_Côte d'Ivoire</td>\n",
       "      <td>Air_Côte d'Ivoire</td>\n",
       "      <td>Abbott GmbH &amp; Co. KG_Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>108-VN-T01</td>\n",
       "      <td>Pre-PQ Process</td>\n",
       "      <td>SCMS-78</td>\n",
       "      <td>ASN-50</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>...</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Ranbaxy, Paonta Shahib, India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1855</td>\n",
       "      <td>16007.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUN PHARMACEUTICAL INDUSTRIES LTD (RANBAXY LAB...</td>\n",
       "      <td>Air_Vietnam</td>\n",
       "      <td>SUN PHARMACEUTICAL INDUSTRIES LTD (RANBAXY LAB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>108-VN-T01</td>\n",
       "      <td>Pre-PQ Process</td>\n",
       "      <td>SCMS-81</td>\n",
       "      <td>ASN-55</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>PMO - US</td>\n",
       "      <td>Direct Drop</td>\n",
       "      <td>EXW</td>\n",
       "      <td>Air</td>\n",
       "      <td>...</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Aurobindo Unit III, India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7590</td>\n",
       "      <td>45450.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aurobindo Pharma Limited_Vietnam</td>\n",
       "      <td>Air_Vietnam</td>\n",
       "      <td>Aurobindo Pharma Limited_Air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Project Code            PQ # PO / SO # ASN/DN #        Country  \\\n",
       "0   1   100-CI-T01  Pre-PQ Process    SCMS-4    ASN-8  Côte d'Ivoire   \n",
       "1   3   108-VN-T01  Pre-PQ Process   SCMS-13   ASN-85        Vietnam   \n",
       "2   4   100-CI-T01  Pre-PQ Process   SCMS-20   ASN-14  Côte d'Ivoire   \n",
       "3  15   108-VN-T01  Pre-PQ Process   SCMS-78   ASN-50        Vietnam   \n",
       "4  16   108-VN-T01  Pre-PQ Process   SCMS-81   ASN-55        Vietnam   \n",
       "\n",
       "  Managed By  Fulfill Via Vendor INCO Term Shipment Mode  ... Pack Price  \\\n",
       "0   PMO - US  Direct Drop              EXW           Air  ...      29.00   \n",
       "1   PMO - US  Direct Drop              EXW           Air  ...       6.20   \n",
       "2   PMO - US  Direct Drop              FCA           Air  ...      80.00   \n",
       "3   PMO - US  Direct Drop              EXW           Air  ...       3.99   \n",
       "4   PMO - US  Direct Drop              EXW           Air  ...       3.20   \n",
       "\n",
       "  Unit Price             Manufacturing Site First Line Designation  \\\n",
       "0       0.97     Ranbaxy Fine Chemicals LTD                    Yes   \n",
       "1       0.03      Aurobindo Unit III, India                    Yes   \n",
       "2       0.80  ABBVIE GmbH & Co.KG Wiesbaden                    Yes   \n",
       "3       0.07  Ranbaxy, Paonta Shahib, India                    Yes   \n",
       "4       0.05      Aurobindo Unit III, India                    Yes   \n",
       "\n",
       "  Weight (Kilograms) Freight Cost (USD) Line Item Insurance (USD)  \\\n",
       "0                 13             780.34                       NaN   \n",
       "1                358             4521.5                       NaN   \n",
       "2                171            1653.78                       NaN   \n",
       "3               1855           16007.06                       NaN   \n",
       "4               7590           45450.08                       NaN   \n",
       "\n",
       "                                vendor_country_combo mode_country_combo  \\\n",
       "0          RANBAXY Fine Chemicals LTD._Côte d'Ivoire  Air_Côte d'Ivoire   \n",
       "1                   Aurobindo Pharma Limited_Vietnam        Air_Vietnam   \n",
       "2                 Abbott GmbH & Co. KG_Côte d'Ivoire  Air_Côte d'Ivoire   \n",
       "3  SUN PHARMACEUTICAL INDUSTRIES LTD (RANBAXY LAB...        Air_Vietnam   \n",
       "4                   Aurobindo Pharma Limited_Vietnam        Air_Vietnam   \n",
       "\n",
       "                                   vendor_mode_combo  \n",
       "0                    RANBAXY Fine Chemicals LTD._Air  \n",
       "1                       Aurobindo Pharma Limited_Air  \n",
       "2                           Abbott GmbH & Co. KG_Air  \n",
       "3  SUN PHARMACEUTICAL INDUSTRIES LTD (RANBAXY LAB...  \n",
       "4                       Aurobindo Pharma Limited_Air  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Additional Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created:\n",
      "- vendor_country_combo: 361 unique values\n",
      "- mode_country_combo: 97 unique values\n",
      "- vendor_mode_combo: 102 unique values\n"
     ]
    }
   ],
   "source": [
    "# Interaction features\n",
    "# Vendor-Country combination (encode as categorical)\n",
    "df['vendor_country_combo'] = df['Vendor'].astype(str) + '_' + df['Country'].astype(str)\n",
    "\n",
    "# Shipment mode-Country combination\n",
    "df['mode_country_combo'] = df['Shipment Mode'].astype(str) + '_' + df['Country'].astype(str)\n",
    "\n",
    "# Vendor-Mode combination\n",
    "df['vendor_mode_combo'] = df['Vendor'].astype(str) + '_' + df['Shipment Mode'].astype(str)\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "print(f\"- vendor_country_combo: {df['vendor_country_combo'].nunique()} unique values\")\n",
    "print(f\"- mode_country_combo: {df['mode_country_combo'].nunique()} unique values\")\n",
    "print(f\"- vendor_mode_combo: {df['vendor_mode_combo'].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ratio features\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create weight to cost ratio (efficiency metric)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_to_cost_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight (Kilograms)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreight Cost (USD)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m)  \u001b[38;5;66;03m# +1 to avoid division by zero\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Value density (value per weight)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_density\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLine Item Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight (Kilograms)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:6146\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6145\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/base.py:1391\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1391\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:182\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    179\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 182\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    185\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# Ratio features\n",
    "# Create weight to cost ratio (efficiency metric)\n",
    "df['weight_to_cost_ratio'] = df['Weight (Kilograms)'] / (df['Freight Cost (USD)'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# Value density (value per weight)\n",
    "df['value_density'] = df['Line Item Value'] / (df['Weight (Kilograms)'] + 0.1)\n",
    "\n",
    "# Lead time to delivery ratio\n",
    "df['lead_time_ratio'] = df['lead_time_days'] / (df['delay_days'].abs() + 1)\n",
    "\n",
    "print(\"\\nRatio features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_high_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLine Item Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLine Item Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Heavy shipment indicator\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_heavy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight (Kilograms)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight (Kilograms)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Urgent shipment (air mode)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_air_shipment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShipment Mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAir\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:2898\u001b[0m, in \u001b[0;36mSeries.quantile\u001b[0;34m(self, q, interpolation)\u001b[0m\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;66;03m# We dispatch to DataFrame so that core.internals only has to worry\u001b[39;00m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;66;03m#  about 2D cases.\u001b[39;00m\n\u001b[1;32m   2896\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m-> 2898\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2900\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:12153\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[0;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[1;32m  12147\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m  12149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(q):\n\u001b[1;32m  12150\u001b[0m     \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n\u001b[1;32m  12151\u001b[0m     \u001b[38;5;66;03m# error: List item 0 has incompatible type \"float | ExtensionArray |\u001b[39;00m\n\u001b[1;32m  12152\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any] | Index | Series | Sequence[float]\"; expected \"float\"\u001b[39;00m\n\u001b[0;32m> 12153\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12154\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[list-item]\u001b[39;49;00m\n\u001b[1;32m  12155\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12157\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  12159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  12160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  12161\u001b[0m         res \u001b[38;5;241m=\u001b[39m res_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:12198\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[0;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[1;32m  12194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m  12195\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Method must be in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  12196\u001b[0m     )\n\u001b[1;32m  12197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m> 12198\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  12199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  12200\u001b[0m     valid_interpolation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:1548\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[0;34m(self, qs, interpolation)\u001b[0m\n\u001b[1;32m   1545\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   1546\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m-> 1548\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1549\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation) \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m   1550\u001b[0m ]\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:1549\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1545\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   1546\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1548\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1549\u001b[0m     \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m   1550\u001b[0m ]\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:1957\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[0;34m(self, qs, interpolation)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_list_like(qs)  \u001b[38;5;66;03m# caller is responsible for this\u001b[39;00m\n\u001b[0;32m-> 1957\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mquantile_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;66;03m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;66;03m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m result \u001b[38;5;241m=\u001b[39m ensure_block_shape(result, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/quantile.py:39\u001b[0m, in \u001b[0;36mquantile_compat\u001b[0;34m(values, qs, interpolation)\u001b[0m\n\u001b[1;32m     37\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m na_value_for_dtype(values\u001b[38;5;241m.\u001b[39mdtype, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquantile_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/quantile.py:97\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[0;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[1;32m     95\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(flat, \u001b[38;5;28mlen\u001b[39m(values))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(values), \u001b[38;5;28mlen\u001b[39m(qs))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_nanpercentile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result)\n\u001b[1;32m    106\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/quantile.py:218\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[0;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: No overload variant of \"percentile\" matches argument types\u001b[39;49;00m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;49;00m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;49;00m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:4287\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[0m\n\u001b[1;32m   4284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(weights \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   4285\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4288\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:4676\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[0m\n\u001b[1;32m   4667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4668\u001b[0m                         q,\n\u001b[1;32m   4669\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4673\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4674\u001b[0m                         weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4675\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4677\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4678\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4679\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4680\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4681\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4682\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4683\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4684\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:3764\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3761\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3762\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3764\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:4853\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, weights, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4851\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   4852\u001b[0m         wgt \u001b[38;5;241m=\u001b[39m weights\n\u001b[0;32m-> 4853\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4854\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4855\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4856\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4857\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4858\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:4985\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out, weights)\u001b[0m\n\u001b[1;32m   4983\u001b[0m         result_shape \u001b[38;5;241m=\u001b[39m virtual_indexes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4984\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mreshape(result_shape)\n\u001b[0;32m-> 4985\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_lerp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4986\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4987\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4988\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4990\u001b[0m     \u001b[38;5;66;03m# Weighted case\u001b[39;00m\n\u001b[1;32m   4991\u001b[0m     \u001b[38;5;66;03m# This implements method=\"inverted_cdf\", the only supported weighted\u001b[39;00m\n\u001b[1;32m   4992\u001b[0m     \u001b[38;5;66;03m# method, which needs to sort anyway.\u001b[39;00m\n\u001b[1;32m   4993\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(weights)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_function_base_impl.py:4779\u001b[0m, in \u001b[0;36m_lerp\u001b[0;34m(a, b, t, out)\u001b[0m\n\u001b[1;32m   4765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_lerp\u001b[39m(a, b, t, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4766\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4767\u001b[0m \u001b[38;5;124;03m    Compute the linear interpolation weighted by gamma on each point of\u001b[39;00m\n\u001b[1;32m   4768\u001b[0m \u001b[38;5;124;03m    two same shape array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4777\u001b[0m \u001b[38;5;124;03m        Output array.\u001b[39;00m\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4779\u001b[0m     diff_b_a \u001b[38;5;241m=\u001b[39m \u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4780\u001b[0m     \u001b[38;5;66;03m# asanyarray is a stop-gap until gh-13105\u001b[39;00m\n\u001b[1;32m   4781\u001b[0m     lerp_interpolation \u001b[38;5;241m=\u001b[39m asanyarray(add(a, diff_b_a \u001b[38;5;241m*\u001b[39m t, out\u001b[38;5;241m=\u001b[39mout))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Boolean features\n",
    "# High value shipment indicator\n",
    "df['is_high_value'] = (df['Line Item Value'] > df['Line Item Value'].quantile(0.75)).astype(int)\n",
    "\n",
    "# Heavy shipment indicator\n",
    "df['is_heavy'] = (df['Weight (Kilograms)'] > df['Weight (Kilograms)'].quantile(0.75)).astype(int)\n",
    "\n",
    "# Urgent shipment (air mode)\n",
    "df['is_air_shipment'] = (df['Shipment Mode'] == 'Air').astype(int)\n",
    "\n",
    "# Long lead time indicator\n",
    "df['is_long_lead_time'] = (df['lead_time_days'] > 30).astype(int)\n",
    "\n",
    "print(\"\\nBoolean features created:\")\n",
    "print(f\"- High value shipments: {df['is_high_value'].sum():,}\")\n",
    "print(f\"- Heavy shipments: {df['is_heavy'].sum():,}\")\n",
    "print(f\"- Air shipments: {df['is_air_shipment'].sum():,}\")\n",
    "print(f\"- Long lead time: {df['is_long_lead_time'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy for handling missing values\n",
    "# For numerical columns: impute with median\n",
    "# For categorical columns: create 'Unknown' category\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target and ID columns from imputation\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['is_late', 'delay_days', 'ID']]\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Imputed {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# Impute categorical columns with 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna('Unknown', inplace=True)\n",
    "        print(f\"Imputed {col} with 'Unknown'\")\n",
    "\n",
    "\n",
    "print(f\"\\nMissing values after imputation: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(\"=\"*60)\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary.head(20))\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy for handling missing values\n",
    "# For numerical columns: impute with median\n",
    "# For categorical columns: create 'Unknown' category\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target and ID columns from imputation\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['is_late', 'delay_days', 'ID']]\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Imputed {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# Impute categorical columns with 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna('Unknown', inplace=True)\n",
    "        print(f\"Imputed {col} with 'Unknown'\")\n",
    "\n",
    "print(f\"\\nMissing values after imputation: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection - Identify Relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to use for ML\n",
    "# Exclude: ID columns, target, delay_days, date columns, raw text fields\n",
    "\n",
    "exclude_cols = [\n",
    "    'ID', 'is_late', 'delay_days',\n",
    "    'PQ First Sent to Client Date', 'PO Sent to Vendor Date',\n",
    "    'Scheduled Delivery Date', 'Delivered to Client Date', 'Delivery Recorded Date',\n",
    "    'PQ #', 'PO / SO #', 'ASN/DN #',\n",
    "    'Item Description', 'Molecule/Test Type', 'Brand',  # High cardinality text\n",
    "    'delivery_year_month'  # Period object\n",
    "]\n",
    "\n",
    "# Get all columns\n",
    "all_cols = df.columns.tolist()\n",
    "\n",
    "# Feature columns (exclude target and non-predictive)\n",
    "feature_cols = [col for col in all_cols if col not in exclude_cols]\n",
    "\n",
    "print(f\"Total columns: {len(all_cols)}\")\n",
    "print(f\"Feature columns: {len(feature_cols)}\")\n",
    "print(f\"Excluded columns: {len(exclude_cols)}\")\n",
    "\n",
    "# Separate numerical and categorical features\n",
    "numerical_features = [col for col in feature_cols if df[col].dtype in [np.int64, np.float64]]\n",
    "categorical_features = [col for col in feature_cols if df[col].dtype == 'object']\n",
    "\n",
    "print(f\"\\nNumerical features: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with target\n",
    "# Add target back temporarily for correlation analysis\n",
    "X_train_with_target = X_train.copy()\n",
    "X_train_with_target['is_late'] = y_train.values\n",
    "\n",
    "# Compute correlations with target\n",
    "correlations = X_train_with_target.corr()['is_late'].drop('is_late').sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 Features Correlated with Delay:\")\n",
    "print(\"=\"*60)\n",
    "print(correlations.head(20))\n",
    "\n",
    "print(\"\\nTop 20 Features Negatively Correlated with Delay:\")\n",
    "print(\"=\"*60)\n",
    "print(correlations.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualze top correlations (minor typo)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Top 15 positive and negative correlations\n",
    "top_corr = pd.concat([correlations.head(15), correlations.tail(15)])\n",
    "\n",
    "plt.barh(range(len(top_corr)), top_corr.values)\n",
    "plt.yticks(range(len(top_corr)), top_corr.index, fontsize=8)\n",
    "plt.xlabel('Correlation with Delay')\n",
    "plt.title('Top Features Correlated with Delivery Delays')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for encoding\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# One-hot encode low cardinality columns\n",
    "if len(low_cardinality_cols) > 0:\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=low_cardinality_cols, prefix=low_cardinality_cols, drop_first=True)\n",
    "    print(f\"One-hot encoding applied to {len(low_cardinality_cols)} columns\")\n",
    "\n",
    "print(f\"Shape after one-hot encoding: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encode high cardinality columns\n",
    "# Note: In production, fit on train set only to avoid leakage\n",
    "# Here we'll do a simple train-test split first\n",
    "\n",
    "# Create train/test split\n",
    "train_df, test_df = train_test_split(df_encoded, test_size=0.2, random_state=42, stratify=df_encoded['is_late'])\n",
    "\n",
    "print(f\"Train set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")\n",
    "print(f\"\\nTrain delay rate: {train_df['is_late'].mean():.2%}\")\n",
    "print(f\"Test delay rate: {test_df['is_late'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply target encoding to high cardinality columns\n",
    "if len(high_cardinality_cols) > 0:\n",
    "    # Fit target encoder on training data\n",
    "    target_encoder = TargetEncoder(cols=high_cardinality_cols)\n",
    "    \n",
    "    # Fit on train\n",
    "    train_df[high_cardinality_cols] = target_encoder.fit_transform(\n",
    "        train_df[high_cardinality_cols], \n",
    "        train_df['is_late']\n",
    "    )\n",
    "    \n",
    "    # Transform test\n",
    "    test_df[high_cardinality_cols] = target_encoder.transform(\n",
    "        test_df[high_cardinality_cols]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTarget encoding applied to {len(high_cardinality_cols)} columns\")\n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Final Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# Get feature column names (excluding target and metadata)\n",
    "final_exclude = ['is_late', 'delay_days', 'ID'] + [\n",
    "    col for col in train_df.columns if 'Date' in col or col in ['PQ #', 'PO / SO #', 'ASN/DN #', 'delivery_year_month']\n",
    "]\n",
    "\n",
    "feature_columns = [col for col in train_df.columns if col not in final_exclude]\n",
    "\n",
    "# Create feature matrices\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df['is_late']\n",
    "\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df['is_late']\n",
    "\n",
    "print(f\"Final feature matrix:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"\\nTotal features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining missing values or infinites\n",
    "print(\"Data quality check:\")\n",
    "print(f\"Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"Infinite values in X_train: {np.isinf(X_train.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "print(f\"Infinite values in X_test: {np.isinf(X_test.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Replace any infinites with NaN, then fill with 0\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(\"\\nAfter cleanup:\")\n",
    "print(f\"Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns in final feature matrix\n",
    "numerical_feature_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numerical features to scale: {len(numerical_feature_cols)}\")\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on train, transform both\n",
    "X_train[numerical_feature_cols] = scaler.fit_transform(X_train[numerical_feature_cols])\n",
    "X_test[numerical_feature_cols] = scaler.transform(X_test[numerical_feature_cols])\n",
    "\n",
    "print(\"\\nFeatures scaled using StandardScaler\")\n",
    "print(f\"Mean of scaled features (should be ~0): {X_train[numerical_feature_cols].mean().mean():.6f}\")\n",
    "print(f\"Std of scaled features (should be ~1): {X_train[numerical_feature_cols].std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with target\n",
    "# Add target back temporarily for correlation analysis\n",
    "X_train_with_target = X_train.copy()\n",
    "X_train_with_target['is_late'] = y_train.values\n",
    "\n",
    "# Compute correlations with target\n",
    "correlations = X_train_with_target.corr()['is_late'].drop('is_late').sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 Features Correlated with Delay:\")\n",
    "print(\"=\"*60)\n",
    "print(correlations.head(20))\n",
    "\n",
    "print(\"\\nTop 20 Features Negatively Correlated with Delay:\")\n",
    "print(\"=\"*60)\n",
    "print(correlations.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Top 15 positive and negative correlations\n",
    "top_corr = pd.concat([correlations.head(15), correlations.tail(15)])\n",
    "\n",
    "plt.barh(range(len(top_corr)), top_corr.values)\n",
    "plt.yticks(range(len(top_corr)), top_corr.index, fontsize=8)\n",
    "plt.xlabel('Correlation with Delay')\n",
    "plt.title('Top Features Correlated with Delivery Delays')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for highly correlated features (multicollinearity)\n",
    "# Calculate correlation matrix for numerical features only\n",
    "corr_matrix = X_train[numerical_feature_cols].corr().abs()\n",
    "\n",
    "# Find pairs with correlation > 0.9\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.9:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(f\"\\nHighly correlated feature pairs (>0.9): {len(high_corr_pairs)}\")\n",
    "if len(high_corr_pairs) > 0:\n",
    "    print(\"\\nTop 10 highly correlated pairs:\")\n",
    "    for feat1, feat2, corr in sorted(high_corr_pairs, key=lambda x: x[2], reverse=True)[:10]:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No highly correlated pairs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Feature Importance (Simple Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Train a simple random forest for feature importance\n",
    "print(\"Training quick Random Forest for feature importance...\")\n",
    "rf_quick = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_quick.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_quick.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Evaluate quick model\n",
    "y_pred_proba = rf_quick.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nQuick RF Model ROC-AUC: {auc:.4f}\")\n",
    "print(f\"\\nTop 20 Important Features:\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'].values)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'].values, fontsize=9)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Features by Random Forest Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test sets\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False, header=True)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False, header=True)\n",
    "\n",
    "print(\"Processed data saved:\")\n",
    "print(\"  - ../data/processed/X_train.csv\")\n",
    "print(\"  - ../data/processed/X_test.csv\")\n",
    "print(\"  - ../data/processed/y_train.csv\")\n",
    "print(\"  - ../data/processed/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature names for reference\n",
    "feature_names_df = pd.DataFrame({\n",
    "    'feature_name': X_train.columns,\n",
    "    'feature_type': X_train.dtypes.astype(str)\n",
    "})\n",
    "feature_names_df.to_csv('../data/processed/feature_names.csv', index=False)\n",
    "\n",
    "print(\"\\nFeature names saved to: ../data/processed/feature_names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY - FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. Input Data:\")\n",
    "print(f\"   - Rows: {df.shape[0]:,}\")\n",
    "print(f\"   - Original columns: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n2. Features Created:\")\n",
    "print(f\"   - Interaction features: 3 (vendor_country, mode_country, vendor_mode)\")\n",
    "print(f\"   - Ratio features: 3 (weight_to_cost, value_density, lead_time_ratio)\")\n",
    "print(f\"   - Boolean features: 4 (high_value, heavy, air, long_lead_time)\")\n",
    "print(f\"   - Time features: 2 (weekend, season)\")\n",
    "\n",
    "print(f\"\\n3. Encoding:\")\n",
    "print(f\"   - One-hot encoded: {len(low_cardinality_cols)} low-cardinality columns\")\n",
    "print(f\"   - Target encoded: {len(high_cardinality_cols)} high-cardinality columns\")\n",
    "\n",
    "print(f\"\\n4. Final Dataset:\")\n",
    "print(f\"   - Training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"   - Test samples: {X_test.shape[0]:,}\")\n",
    "print(f\"   - Total features: {X_train.shape[1]}\")\n",
    "print(f\"   - Numerical features scaled: {len(numerical_feature_cols)}\")\n",
    "\n",
    "print(f\"\\n5. Data Quality:\")\n",
    "print(f\"   - Missing values: 0\")\n",
    "print(f\"   - Infinite values: 0\")\n",
    "print(f\"   - Target balance - Train: {y_train.mean():.2%}\")\n",
    "print(f\"   - Target balance - Test: {y_test.mean():.2%}\")\n",
    "\n",
    "print(f\"\\n6. Quick Model Performance:\")\n",
    "print(f\"   - Random Forest ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\n7. Top 5 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"   - {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\n8. Next Steps:\")\n",
    "print(\"   - Notebook 4: Baseline Models (Logistic Regression, Decision Tree)\")\n",
    "print(\"   - Notebook 5: Advanced Models (Random Forest, XGBoost, LightGBM)\")\n",
    "print(\"   - Notebook 6: Model Evaluation and Selection\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
